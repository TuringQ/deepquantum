# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.19.1
#   kernelspec:
#     display_name: dq_draw
#     language: python
#     name: python3
# ---

# %% [markdown]
#
# å˜åˆ†é«˜æ–¯ç»è‰²é‡‡æ ·çš„è®­ç»ƒ
# ======================================
#
#
# *å‰ç½®æ¨¡å—*
#
# [å…³äºç»è‰²é‡‡æ ·çš„ä»‹ç»](https://github.com/TuringQ/deepquantum/tree/main/examples/demos/gbs/boson_sampling/boson_sampling.ipynb)
#
#
# [å…³äºé«˜æ–¯ç»è‰²é‡‡æ ·çš„ä»‹ç»](https://github.com/TuringQ/deepquantum/tree/main/examples/demos/gbs/gaussian_boson_sampling/gaussian_boson_sampling.ipynb)
#
# å¼•è¨€
# ------
#
# å—åˆ°æœºå™¨å­¦ä¹ ä¸­ç¥ç»ç½‘ç»œæˆåŠŸçš„å¯å‘ï¼Œè®¸å¤šåº”ç”¨å±‚é¢çš„é‡å­ç®—æ³•ä¾èµ–äºå˜åˆ†é‡å­çº¿è·¯çš„è®­ç»ƒï¼ŒåŒ…æ‹¬ï¼š
#
# 1. **é‡å­ç¥ç»ç½‘ç»œï¼ˆQuantum Neural Networks, QNNsï¼‰**ï¼šä¸€ç±»æ¨¡ä»¿ç»å…¸ç¥ç»ç½‘ç»œç»“æ„çš„é‡å­ç®—æ³•ï¼Œå®ƒä»¬ä½¿ç”¨å¯å˜åˆ†çš„é‡å­ç½‘ç»œæ¥è¡¨ç¤ºä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨é‡å­åŠ›å­¦åŸç†è¿›è¡Œä¿¡æ¯å¤„ç†ã€‚
#
# 2. **é‡å­æ”¯æŒå‘é‡æœºï¼ˆQuantum Support Vector Machine, QSVMï¼‰**ï¼šä½¿ç”¨å˜åˆ†é‡å­çº¿è·¯å®šä¹‰æ ¸å‡½æ•°ï¼Œç”¨äºè§£å†³å‡¸ä¼˜åŒ–ã€åˆ†ç±»é—®é¢˜ç­‰ã€‚
#
# 3. **é‡å­è¿‘ä¼¼ä¼˜åŒ–ç®—æ³•ï¼ˆQuantum Approximate Optimization Algorithm, QAOAï¼‰**ï¼šé€šè¿‡è°ƒæ•´é‡å­çº¿è·¯çš„å‚æ•°æ¥æ‰¾åˆ°ä¼˜åŒ–é—®é¢˜çš„è¿‘ä¼¼æœ€ä¼˜è§£ã€‚
#
# 4. **å˜åˆ†é‡å­æœ¬å¾æ±‚è§£å™¨ï¼ˆVariational Quantum Eigensolver, VQEï¼‰**ï¼šä¸€ç§ç”¨äºæ±‚è§£åˆ†å­èƒ½é‡åŸºæ€é—®é¢˜çš„é‡å­ç®—æ³•ï¼Œé€šè¿‡è®­ç»ƒé‡å­çº¿è·¯çš„å‚æ•°æ¥è¿‘ä¼¼å“ˆå¯†é¡¿é‡çš„æœ€ä½æœ¬å¾å€¼ã€‚
#
# 5. **é‡å­æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆQuantum Machine Learning Algorithmsï¼‰**ï¼šä½¿ç”¨å¯å˜åˆ†çš„é‡å­ç®—æ³•æ¥åŠ é€Ÿæœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚é‡å­æ•°æ®ç¼–ç ã€é‡å­ç‰¹å¾æå–ç­‰ã€‚
#
# 6. **é‡å­éšæœºç‰¹å¾ï¼ˆQuantum Random Feature, QRFï¼‰**ï¼šå°†é‡å­è®¡ç®—ä¸ç»å…¸æœºå™¨å­¦ä¹ æ¨¡å‹ç»“åˆçš„æ–¹æ³•ï¼Œé€šè¿‡é‡å­çº¿è·¯ç”Ÿæˆé«˜ç»´ç©ºé—´ä¸­çš„éšæœºç‰¹å¾ï¼Œä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
#
# åœ¨DeepQuantumå¸¸è§„é‡å­çº¿è·¯ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿå·²ç»å±•ç¤ºäº†è‹¥å¹²ä»ç®€å•ã€ä¸­çº§åˆ°å›°éš¾çš„å˜åˆ†é‡å­ç®—æ³•çš„æ¡ˆä¾‹ğŸ‘‡
#
# [å˜åˆ†é‡å­ç®—æ³•æ¡ˆä¾‹](https://deepquantum.turingq.com/category/quantum-variational-algorithm/)
#
# å¯¹äºå…‰é‡å­æ¨¡å—ï¼Œ[å…‰é‡å­å…¥é—¨ä»‹ç»](https://github.com/TuringQ/deepquantum/blob/main/tutorials/photonic_basics.ipynb) æ¼”ç¤ºäº†å¦‚ä½•æ­å»ºå«å‚æ•°çš„å…‰é‡å­çº¿è·¯ï¼Œå¹¶ç”¨Fockåç«¯è¿›è¡Œé‡‡æ ·æµ‹é‡ã€‚
#
# é‚£ä¹ˆï¼Œå¯¹äºç‹¬å…·ç‰¹è‰²çš„é«˜æ–¯ç»è‰²é‡‡æ ·ï¼ˆGaussian Boson Samplingï¼Œç®€ç§°GBSï¼‰ä»»åŠ¡ï¼Œæˆ‘ä»¬æ˜¯å¦ä¹Ÿèƒ½å®Œæˆå¯¹äºå˜åˆ†çº¿è·¯çš„æ„å»ºå’Œè®­ç»ƒå‘¢ï¼Ÿ
#
#

# %% [markdown]
#
# ç†è®ºåŸºç¡€
# ------
#
# åœ¨[å…³äºé«˜æ–¯ç»è‰²é‡‡æ ·çš„ä»‹ç»](https://github.com/TuringQ/deepquantum/tree/main/examples/gbs/gaussian_boson_sampling/gaussian_boson_sampling.ipynb)ä¸­ï¼Œæˆ‘ä»¬å¯¹é«˜æ–¯ç»è‰²é‡‡æ ·ï¼ˆGBSï¼‰è¿›è¡Œäº†ç»†è‡´çš„ä»‹ç»ã€‚å½¢å¦‚[ç»è‰²é‡‡æ ·](https://github.com/TuringQ/deepquantum/tree/main/examples/gbs/boson_sampling/boson_sampling.ipynb)çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¯¹äºGBSè®¾å¤‡ï¼Œè§‚å¯Ÿåˆ°ç‰¹å®šè¾“å‡ºåˆ†å¸ƒ$S$çš„æ¦‚ç‡$\Pr(S)$å¦‚ä¸‹ï¼š
#
# \begin{equation*}
# \Pr(S) = \frac{1}{\mathcal{N}} \frac{|\text{Haf}(A_S)|^2}{s_1!\ldots s_m!},
# \end{equation*}
#
# å…¶ä¸­ï¼Œ$S=(s_1, s_2, \ldots, s_m)$,  $s_i$æ˜¯åœ¨ç¬¬$i$ä¸ªmodeæ¢æµ‹åˆ°çš„å…‰å­æ•°ã€‚
# è€Œ$\mathcal{N}$ æ˜¯ä¸€ä¸ªå½’ä¸€åŒ–å¸¸æ•°ï¼Œ$A$æ˜¯ä¸€ä¸ªä»»æ„çš„ç‰¹å¾å€¼åœ¨ $-1$ å’Œ$1$é—´çš„å¯¹ç§°çŸ©é˜µã€‚
# çŸ©é˜µ $A$ä¹Ÿå¯ä»¥é€šè¿‡ä¸€ä¸ªå¸¸æ•°å› å­è¿›è¡Œé‡æ–°ç¼©æ”¾ï¼Œç›¸å½“äºå®šä¹‰åœ¨ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒä¸­æ€»çš„å¹³å‡å…‰å­æ•°ã€‚
#
# æˆ‘ä»¬å¸Œæœ›å¯¹è¿™ç§åˆ†å¸ƒè¿›è¡Œ**è®­ç»ƒ**ï¼Œä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œå¸Œæœ›å†ç°ç»™å®šæ•°æ®é›†çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œæˆ–è€…ä¼˜åŒ–çº¿è·¯ä»¥é«˜æ¦‚ç‡é‡‡æ ·ç‰¹å®šæ¨¡å¼ã€‚ä»¥æ­¤ï¼Œä»»ä½•å˜åˆ†é‡å­ç®—æ³•éƒ½æœ‰å¯èƒ½åœ¨GBSè®¾å¤‡ä¸Šå®ç°ã€‚
#
# ç”¨æ•°å­¦éšæœºä¼˜åŒ–æ¨¡å‹æ¥è¡¨ç¤ºï¼Œç»™å®šä¸€ä¸ªå‡½æ•°$h(S)$å’Œå‚æ•°$\theta$ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é‡‡æ ·å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ$P_{\theta}(S)$ã€‚è€Œä»»åŠ¡çš„ç›®æ ‡åˆ™æ˜¯æ‰¾åˆ°åˆé€‚çš„å‚æ•°$\theta$ï¼Œæ¥æœ€å°åŒ–å¦‚ä¸‹æœŸæœ›å€¼ï¼š
#
# \begin{equation*}
# C (\theta) = \sum_{S} h(S) P_{\theta}(S).
# \end{equation*}
#
# æ­¤æ¡ˆä¾‹å°†èšç„¦ä¸€ä¸ªç®€å•çš„5èŠ‚ç‚¹çš„æ£’æ£’ç³–ğŸ­å›¾ã€‚é€šè¿‡å˜åˆ†é«˜æ–¯ç»è‰²é‡‡æ ·çš„è®­ç»ƒï¼Œæˆ‘ä»¬æœŸæœ›åœ¨ç‰¹å®šçš„èŠ‚ç‚¹è§‚å¯Ÿåˆ°å°½å¯èƒ½å¤šçš„å…‰å­ï¼Œè€Œåœ¨åˆ«çš„èŠ‚ç‚¹è§‚å¯Ÿåˆ°å°½é‡å°‘çš„å…‰å­ã€‚
#
#
# å®Œæˆæ­¤å˜åˆ†æ¡ˆä¾‹éœ€è¦ä»¥ä¸‹3æ­¥ï¼šï¼ˆiï¼‰é€‰ç”¨åˆé€‚çš„æ–¹æ³•ç¼–ç å‚æ•°ï¼›ï¼ˆiiï¼‰è°ƒç”¨DeepQuantumæ¨¡å—å®ŒæˆGBSé‡‡æ ·æ¨¡æ‹Ÿï¼›ï¼ˆiiiï¼‰æ ¹æ®é‡‡æ ·ç»“æœï¼Œé€‰å–åˆé€‚æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨å®Œæˆä¼˜åŒ–ã€‚
#
#
#

# %% [markdown]
# é—®é¢˜è½¬åŒ–ä¸å‚æ•°åŒ–
# -----------------------
# æˆ‘ä»¬å°†ä¼šè°ƒç”¨DeepQuantumä¸­GBSæ¨¡å—ï¼Œè¯¦æƒ…å¯è§[APIæ–‡æ¡£](https://dqapi.turingq.com/deepquantum.photonic.html#deepquantum.photonic.ansatz.GBS_Graph)
#
# é¦–å…ˆè°ƒç”¨DeepQauntumå’Œç›¸å…³åŒ…ï¼š

# %%
import deepquantum as dq
import matplotlib.pyplot as plt
import networkx as nx
import torch
import torch.nn as nn

# %% [markdown]
# è°ƒç”¨networkxåŒ…ä»¥ç”Ÿæˆ5èŠ‚ç‚¹çš„æ£’æ£’ç³–ğŸ­å›¾ï¼Œå¹¶è·å¾—é‚»æ¥çŸ©é˜µä»¥å¯¹åº”GBSä¸­ç‰¹å¾å€¼åœ¨ $-1$ å’Œ$1$é—´çš„çš„å¯¹ç§°çŸ©é˜µ$A$ã€‚

# %%
graph = nx.lollipop_graph(3, 2)

# è®¡ç®—é‚»æ¥çŸ©é˜µ
a = nx.to_numpy_array(graph)
print('é‚»æ¥çŸ©é˜µA:', a)

# å¯è§†åŒ–å›¾åƒ
nx.draw(graph, with_labels=True)

# %% [markdown]
# æ­¤æ—¶ï¼Œè‹¥æ— å‚æ•°åŒ–éœ€è¦ï¼ŒGBSå¯é€šè¿‡é‚»æ¥çŸ©é˜µ$A$é‡‡æ ·ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒ$P(S)$ï¼š

# %%
gbs = dq.photonic.ansatz.GBS_Graph(adj_mat=a, cutoff=3, mean_photon_num=6)
gbs()

# é«˜æ–¯ç»è‰²é‡‡æ ·
sample = gbs.measure(mcmc=True)
print('é‡‡æ ·ç»“æœä¸ºï¼š', sample)

# è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹ç†è®ºå¹³å‡å…‰å­æ•°
photon_number = gbs.photon_number_mean_var()[0]
print('æ¯ä¸ªèŠ‚ç‚¹å¹³å‡å…‰å­æ•°ä¸ºï¼š', photon_number)

# %% [markdown]
# ä¸ºäº†å®ç°å˜åˆ†ä¼˜åŒ–ï¼Œéœ€è¦ç¼–ç å‚æ•°$\theta$è¿›GBSè®¾å¤‡ï¼Œå³å‚æ•°åŒ–çŸ©é˜µ$A$ã€‚è®ºæ–‡[Training Gaussian Boson Sampling Distributions](https://arxiv.org/abs/2004.04770)ä¸­å¼•å…¥äº†â€œWAWâ€çš„å‚æ•°åŒ–æ–¹å¼ï¼Œå³å°†å¯¹ç§°çŸ©é˜µ$A$è½¬åŒ–ä¸º
#
# \begin{equation*}
# A \rightarrow A_W = W A W,
# \end{equation*}
#
# å…¶ä¸­$W = \text{diag}(\sqrt{w_1}, \sqrt{w_2}, \ldots, \sqrt{w_m})$ æ˜¯å¯¹è§’æƒé‡çŸ©é˜µï¼Œ $m$æ˜¯GBSæ¨¡å¼æ•°ã€‚
# è¿™æ ·çš„æ„é€ æ—¢å¯ä»¥æ–¹ä¾¿çš„é€šè¿‡æƒé‡$w$å®ç°å‚æ•°åŒ–ï¼Œåˆä¿ç•™äº†$A$å¯¹ç§°çš„ç‰¹æ€§ã€‚å¦å¤–ï¼Œåœ¨è®¡ç®—$A_W$çš„hafnianå€¼æ—¶ï¼Œå¯é€šè¿‡ä»¥ä¸‹åˆ†è§£åˆ†ç¦»å‚æ•°åŒ–éƒ¨åˆ†ï¼Œä¸ä¼šé¢å¤–å¢åŠ hafniançš„è®¡ç®—éš¾åº¦ï¼š
#
# \begin{equation*}
# \text{Haf}(A_W) = \text{Haf}(A)\text{det}(W),
# \end{equation*}
#
# äºæ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°ç¼–ç å¯è®­ç»ƒå‚æ•°$\theta = (\theta_1, \ldots, \theta_d)$ è¿›æƒé‡ $w_k$ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬é€‰ç”¨æŒ‡æ•°åµŒå…¥çš„å½¢å¼ï¼Œ
#
# \begin{equation*}
# w_k = \exp(-\theta_k),
# \end{equation*}

# %%
# ç”Ÿæˆåˆå§‹å‚æ•°
nr_modes = len(a)
params = torch.randn(nr_modes, dtype=torch.float64)
print('åˆå§‹åŒ–å‚æ•°ä¸º: ', params)

# ç¼–ç è¿›æƒé‡çŸ©é˜µ
weights = torch.exp(-params)
print('æŒ‡æ•°æƒé‡ä¸º: ', weights)
w = torch.diag(weights)
print('æƒé‡çŸ©é˜µä¸º: ', w)

# å®ç°WAWå‚æ•°åŒ–
waw = w @ torch.tensor(a) @ w
print('WAWçŸ©é˜µä¸º: ', waw)

# %% [markdown]
# è°ƒç”¨DeepQuantumæ¨¡å—å®ŒæˆGBSé‡‡æ ·æ¨¡æ‹Ÿ
# -----------------------
# å¦‚å‰æ¨¡å—æ‰€ç¤ºï¼Œè°ƒç”¨DeepQuantumå®ç°GBSé‡‡æ ·æ¨¡æ‹Ÿååˆ†ä¾¿æ·ã€‚é«˜æ–¯ç»è‰²é‡‡æ ·ï¼ˆGBSï¼‰åˆ†å¸ƒç”±å¯¹ç§°çŸ©é˜µ $A$ å†³å®šï¼Œåœ¨ç»è¿‡WAWæ–¹æ³•å‚æ•°åŒ–åï¼Œæˆ‘ä»¬åªéœ€è¦è¾“å…¥wawçŸ©é˜µã€‚
#
# æ€»çš„å¹³å‡å…‰å­æ•°æ˜¯åˆ†å¸ƒçš„ä¸€ä¸ªè¶…å‚æ•°ï¼šä¸€èˆ¬è€Œè¨€ï¼Œä¸åŒçš„é€‰æ‹©å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒä¸­å¾—åˆ°ä¸åŒçš„ç»“æœã€‚å®é™…ä¸Šï¼Œéšç€æƒé‡è¢«ä¼˜åŒ–ï¼Œå¹³å‡å…‰å­æ•°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œä½†ä¸ä¼šå½±å“æœ€ç»ˆç›¸å¯¹çš„æ¦‚ç‡åˆ†å¸ƒã€‚
#
# æœ€åï¼ŒGBSè®¾å¤‡å¯ä»¥æ“ä½œå…·æœ‰åˆ†è¾¨å…‰å­æ•°èƒ½åŠ›çš„æ¢æµ‹å™¨æˆ–é˜ˆå€¼æ¢æµ‹å™¨ï¼Œè¿™é‡Œæˆ‘ä»¬åªä½¿ç”¨æ¯ä¸ªæ¨¡å¼ä¸Šçš„å¹³å‡å…‰å­æ•°ã€‚

# %%
# æ ¹æ®ç²¾åº¦éœ€æ±‚è®¾å®šcutoff
# è®¾å®šå¹³å‡å…‰å­æ•°ä¸º6ï¼ˆä¹Ÿå¯è®¾ç½®å…¶å®ƒï¼‰
gbs = dq.photonic.GraphGBS(adj_mat=waw, cutoff=3, mean_photon_num=6)
gbs()

# è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹ç†è®ºå¹³å‡å…‰å­æ•°
photon_number = gbs.photon_number_mean_var()[0]
print('æ¯ä¸ªèŠ‚ç‚¹å¹³å‡å…‰å­æ•°ä¸ºï¼š', photon_number)

# %% [markdown]
# é€‰å–æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼Œå®Œæˆä¼˜åŒ–
# -----------------------
# æ ¹æ®æ¡ˆä¾‹å¼€å¤´çš„éœ€æ±‚ï¼Œåœ¨ä¸€ä¸ª5èŠ‚ç‚¹çš„æ£’æ£’ç³–å›¾ä¸­ï¼Œé€šè¿‡å˜åˆ†é«˜æ–¯ç»è‰²é‡‡æ ·çš„è®­ç»ƒï¼Œæˆ‘ä»¬æœŸæœ›åœ¨ç‰¹å®šçš„èŠ‚ç‚¹è§‚å¯Ÿåˆ°å°½å¯èƒ½å¤šçš„å…‰å­ï¼Œè€Œåœ¨åˆ«çš„èŠ‚ç‚¹è§‚å¯Ÿåˆ°å°½é‡å°‘çš„å…‰å­ã€‚ä¸å¤±ä¸€èˆ¬æ€§ï¼Œæˆ‘ä»¬è‡´åŠ›äºå¢åŠ æ£’æ£’ç³–å›¾çš„â€œç³–æœâ€éƒ¨åˆ†ä¸­çš„å…‰å­æ•°ï¼Œè¿™å¯¹åº”äºæ¨¡å¼å­é›†``[0, 1, 2]``ã€‚
#
# æŸå¤±å‡½æ•°çš„æ„å»ºå¾ˆå¤šæ ·ï¼Œå…ˆé‡‡ç”¨æœ€ç®€å•çš„çº¿æ€§æŸå¤±å‡½æ•°ï¼š

# %%
# æ„å»ºæœŸæœ›æ¨¡å¼å­é›†
subset = [0, 1, 2]


# æ„å»ºæŸå¤±å‡½æ•°
def target(s):
    not_subset = [k for k in range(len(s)) if k not in subset]
    return sum(s[not_subset]) - sum(s[subset])


print('losså€¼ä¸º: ', target(photon_number))

# %% [markdown]
# æ¥ä¸‹æ¥ä»…éœ€é€šè¿‡ä¼˜åŒ–å™¨ï¼Œæœ€å°åŒ–æŸå¤±å‡½æ•°çš„å€¼ï¼Œä¾¿å¯å®Œæˆå¯¹äºå˜åˆ†é«˜æ–¯ç»è‰²é‡‡æ ·è®¾å¤‡çš„è®­ç»ƒã€‚
#
# ä¸ºäº†æ–¹ä¾¿è°ƒç”¨ä¼˜åŒ–å™¨ï¼Œæˆ‘ä»¬æ•´åˆä¸Šé¢ä»£ç ï¼Œç»„åˆæˆä¸€ä¸ª`VGBS`çš„`class`ã€‚

# %%
graph = nx.lollipop_graph(3, 2)
a = nx.to_numpy_array(graph)
nr_modes = len(a)
subset = [0, 1, 2]
loss_history = []
result = []


class VGBS(nn.Module):
    def __init__(self):
        super().__init__()
        self.params = nn.Parameter(torch.randn(nr_modes, dtype=torch.float64), requires_grad=False)
        loss_history.clear()

    def target(self, s):
        not_subset = [k for k in range(len(s)) if k not in subset]
        return sum(s[not_subset]) - sum(s[subset])

    def loss(self, x):
        if not isinstance(x, torch.Tensor):
            x = torch.tensor(x).to(self.params.dtype).reshape(-1)
        weights = torch.exp(-x)
        w = torch.diag(weights)
        waw = w @ torch.tensor(a) @ w

        gbs = dq.photonic.GBS_Graph(adj_mat=waw, cutoff=5, mean_photon_num=6)
        gbs()
        photon_number = gbs.photon_number_mean_var()[0]
        print('æ¯ä¸ªèŠ‚ç‚¹å¹³å‡å…‰å­æ•°ä¸º: ', photon_number)
        loss = self.target(photon_number)

        loss_history.append(loss.item())
        result.clear()
        result.append(photon_number.tolist())

        return loss


# %% [markdown]
# é€‰å–DeepQuantumå†…å»ºSPSAä¼˜åŒ–å™¨ï¼Œè®¾å®šä¼˜åŒ–å™¨å‚æ•°ï¼Œå®Œæˆä¼˜åŒ–ã€‚

# %%
# ç”Ÿæˆåˆšåˆ›å»ºçš„VGBSæ¨¡å‹
model = VGBS()

# å®šä¹‰ä¼˜åŒ–å™¨å‚æ•°
spsa_hyperparam = {'a': 1, 'c': 0.01, 'A': 200, 'nepoch': 1000, 'alpha': 0.602, 'gamma': 0.101}
optimizer = dq.optimizer.OptimizerSPSA(model.loss, model.params)
optimizer.set_hyperparam(spsa_hyperparam)
param_best = torch.tensor(optimizer.run(100)).float()

# %% [markdown]
# ç”±ä¼˜åŒ–ç»“æœå¯è§ï¼Œå‰ä¸‰ä¸ªâ€œç³–æœâ€èŠ‚ç‚¹å¹³å‡å…‰å­æ•°å¤§äºâ€œæ£’å­â€èŠ‚ç‚¹å¹³å‡å…‰å­æ•°ï¼Œä¼˜åŒ–æˆåŠŸï¼
#
#

# %% [markdown]
# å¯è§†åŒ–ç»“æœ
# -----------------------
# è°ƒç”¨`matplotlib`åº“ï¼Œç»˜åˆ¶ä¼˜åŒ–è¿‡ç¨‹ä¸­æŸå¤±å‡½æ•°éšè¿­ä»£æ¬¡æ•°ä¸‹é™æ›²çº¿ã€‚
# å¯è§åœ¨è¯¥é—®é¢˜ä¸Šï¼Œè™½ç„¶ä½¿ç”¨çš„æ˜¯éæ¢¯åº¦ç®—æ³•ï¼ŒDeepQuantumè‡ªå¸¦çš„`OptimizerSPSA`ä¼˜åŒ–å™¨æ”¶æ•›éå¸¸è¿…é€Ÿã€‚

# %%
plt.figure(figsize=(10, 6))
plt.plot(loss_history)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss over time')

# %% [markdown]
# ç»˜åˆ¶æ£’æ£’ç³–å›¾æŸ¥çœ‹å˜åˆ†ä¼˜åŒ–ç»“æœã€‚
# å…¶ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„å¤§å°ä»£è¡¨å¹³å‡å…‰å­æ•°çš„å¤šå°‘ã€‚
# æ˜æ˜¾å¯è§ä½äºâ€œç³–æœâ€å¤„çš„å¹³å‡å…‰å­æ•°è¿œé«˜äºâ€œæ£’å­â€ï¼Œå®ç°äº†æœ¬æ¡ˆä¾‹è®­ç»ƒçš„ç›®æ ‡ã€‚

# %%
result_scaled = [x * 800 for x in result[0]]
nx.draw(graph, node_size=result_scaled, with_labels=True)


# %% [markdown]
# é’ˆå¯¹æŸå¤±å‡½æ•°çš„è¿›ä¸€æ­¥æ”¹è¿›
# -----------------------
# æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œåœ¨ä¸Šä¸ªæ¨¡å—ä¸­ï¼Œè™½ç„¶â€œç³–æœâ€èŠ‚ç‚¹å¤„`[0ï¼Œ1ï¼Œ2]`çš„å…‰å­æ•°è¿œé«˜äºå…¶å®ƒèŠ‚ç‚¹ï¼Œä½†å½“å‰çš„ç®€å•çº¿æ€§æŸå¤±å‡½æ•°æ— æ³•å¾ˆå¥½æ§åˆ¶`[0ï¼Œ1ï¼Œ2]`èŠ‚ç‚¹çš„ç›¸å¯¹å…‰å­æ•°ã€‚
# ä¸å¤±ä¸€èˆ¬æ€§ï¼Œæˆ‘ä»¬å¦‚æœé¢å¤–è¦æ±‚`[0ï¼Œ1ï¼Œ2]`èŠ‚ç‚¹çš„å…‰å­æ•°ç›¸ç­‰ï¼Œè¯¥å¦‚ä½•å¤„ç†ï¼Ÿ
#
# å…¶å®ï¼Œè¿™é¡¹ä»»åŠ¡æœ¬è´¨å¯ä»¥è¢«è®¤ä¸ºæ˜¯ï¼šè®­ç»ƒä¸€ä¸ªå˜åˆ†é«˜æ–¯é‡‡æ ·çº¿è·¯ï¼Œä½¿å…¶è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒä¸ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒç›¸ä¸€è‡´ã€‚å¯¹äºæ¦‚ç‡åˆ†å¸ƒçš„è®­ç»ƒå¯ä»¥é€šè¿‡æœ€å°åŒ–Kullback-Leiblerï¼ˆKLï¼‰æ•£åº¦æ¥æ‰§è¡Œï¼Œè¿™åœ¨å»æ‰å¸¸æ•°é¡¹åå¯ä»¥å†™æˆï¼š
#
# \begin{equation*}
# KL(\theta) = -\frac{1}{T}\sum_S \log[P_{\theta}(S)].
# \end{equation*}
#
#
# åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ$ S $ æ˜¯æ¦‚ç‡åˆ†å¸ƒä¸­ä¸€ä¸ªå…ƒç´ ï¼Œ$ P(S) $ æ˜¯ä»GBSåˆ†å¸ƒä¸­æŠ½æ ·æ—¶è§‚å¯Ÿåˆ°è¯¥å…ƒç´ çš„æ¦‚ç‡ï¼Œè€Œ $ T $ æ˜¯å…ƒç´ çš„æ€»æ•°ã€‚
# æ®æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å†™å‡ºæ–°çš„æŸå¤±å‡½æ•°`target_kl`:


# %%
def target_kl(s):
    return -sum(torch.log(s[subset] / 2))


# %% [markdown]
# æ›´æ–°æŸå¤±å‡½æ•°ï¼Œå†æ¬¡å¼€å§‹ä¼˜åŒ–ï¼š


# %%
class VGBS(nn.Module):
    def __init__(self):
        super().__init__()
        self.params = nn.Parameter(torch.randn(nr_modes, dtype=torch.float64), requires_grad=False)
        loss_history.clear()

    # é‡‡ç”¨KLæ•£åº¦å®šä¹‰çš„æŸå¤±å‡½æ•°
    def target_kl(self, s):
        return -sum(torch.log(s[subset] / 2))

    def loss(self, x):
        if not isinstance(x, torch.Tensor):
            x = torch.tensor(x).to(self.params.dtype).reshape(-1)
        weights = torch.exp(-x)
        w = torch.diag(weights)
        waw = w @ torch.tensor(a) @ w

        gbs = dq.photonic.GBS_Graph(adj_mat=waw, cutoff=5, mean_photon_num=6)
        gbs()
        photon_number = gbs.photon_number_mean_var()[0]
        print('æ¯ä¸ªèŠ‚ç‚¹å¹³å‡å…‰å­æ•°ä¸º: ', photon_number)
        loss = self.target_kl(photon_number)

        loss_history.append(loss.item())
        result.clear()
        result.append(photon_number.tolist())

        return loss


model = VGBS()
loss_history = []

# å®šä¹‰ä¼˜åŒ–å™¨å‚æ•°
spsa_hyperparam = {'a': 1, 'c': 0.01, 'A': 200, 'nepoch': 1000, 'alpha': 0.602, 'gamma': 0.101}
optimizer = dq.optimizer.OptimizerSPSA(model.loss, model.params)
optimizer.set_hyperparam(spsa_hyperparam)
param_best = torch.tensor(optimizer.run(1000)).float()

result_scaled = [x * 800 for x in result[0]]
nx.draw(graph, node_size=result_scaled, with_labels=True)

# %% [markdown]
# æ¯ä¸ªâ€œç³–æœâ€èŠ‚ç‚¹è¾“å‡ºè¿‘ä¼¼2ä¸ªå…‰å­ï¼Œè€Œå…¶ä½™èŠ‚ç‚¹å‡ ä¹æ²¡æœ‰è¾“å‡ºå…‰å­ï¼Œä¼˜åŒ–ç»“æœéå¸¸å®Œç¾ï¼

# %% [markdown]
# # é™„å½•

# %% [markdown]
# [1] Leonardo Banchi, NicolÃ¡s Quesada, and Juan Miguel Arrazola. Training Gaussian Boson Sampling Distributions. arXiv:2004.04770. 2020.
